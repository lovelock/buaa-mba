---
title: "多元线性回归中的 R-square 和Ajusted R-square 评判关系"
description: 
date: 2024-09-22T20:34:51+08:00
image: 
math: true
license: 
hidden: false
comments: true
---

多元线性回归是一种用于分析多个自变量与因变量之间关系的统计方法。在这类分析中，评估模型的拟合优度是至关重要的，通常使用决定系数 \( R^2 \) 和调整后的 \( R^2 \) 来进行评估。本文将深入探讨这两个指标的定义、评判关系及其在模型选择中的应用。

## 基础公式

\[
\sum_{i=1}^n(y_i-\bar{y})^2 = \sum_{i=1}^n(\hat{y}-\bar{y})^2 + \sum_{i=1}^n(y_i-\hat{y_i})^2
\]

- $\sum_{i=1}^n(y_i-\bar{y})^2$也叫SST，Sum of Squares of Total。
- $\sum_{i=1}^n(\hat{y}-\bar{y})^2$也叫SSR，Sum of Squares of Regression。
- $\sum_{i=1}^n(y_i-\hat{y_i})^2$也叫SSE，Sum of Squares of Error。

## \( R^2 \) 的定义与特性

\( R^2 \)（决定系数）表示自变量对因变量方差的解释比例，其值范围在 0 到 1 之间。\( R^2 \) 越接近 1，说明模型对数据的拟合效果越好。计算公式为：

\[
R^2 = 1 - \frac{SSE}{SST}
\]

其中，\( SSE \) 是残差平方和，\( SST \) 是总平方和。

从上面的基础公式也可以得到

\[
R^2 = \frac{SST-SSE}{SST} \
=\frac{SSR}{SST}
\]

SSR这部分其实是**可用线性关系解释的自变量占的权重**，那么相应的残差就是不能解释的，所以可解释的部分占比越高，$R^2$就越大。

尽管 \( R^2 \) 是一个直观且易于理解的指标，但它有一个重要的缺陷：随着自变量数目的增加，\( R^2 \) 总是不会减少。即使新增的自变量对因变量没有实际贡献，\( R^2 \) 也可能会增加，这会导致模型过拟合。


## 调整后的 \( R^2 \) 的定义与优势

为了解决 \( R^2 \) 的不足，引入了调整后的 \( R^2 \)（Adjusted \( R^2 \)）。它不仅考虑了模型的拟合优度，还惩罚模型中自变量的数量。调整后的 \( R^2 \) 的计算公式为：

\[
\text{Adjusted } R^2 = 1 - (1 - R^2) \frac{n-1}{n-p-1}
\]

其中，\( n \) 是样本大小，\( p \) 是自变量的数量。调整后的 \( R^2 \) 使得在增加不必要的自变量时，\( R^2 \) 可能上升但调整后的 \( R^2 \) 可能下降，从而更真实地反映模型的解释能力。

## \( R^2 \) 和调整后的 \( R^2 \) 的评判关系

在多元线性回归中，\( R^2 \) 和调整后的 \( R^2 \) 之间的评判关系可以归纳为以下几点：

1. **评估模型的整体表现**：
   - 在比较不同模型时，如果调整后的 \( R^2 \) 增加，通常表明新自变量对模型有显著贡献。这意味着新自变量不仅提高了拟合优度，而且带来了更合理的模型解释。

2. **避免过拟合**：
   - 当增加新的自变量时，若 \( R^2 \) 增加而调整后的 \( R^2 \) 下降，则暗示新自变量可能并不有用，甚至会导致模型的复杂度增加，从而降低模型的解释能力。

3. **模型选择的依据**：
   - 通常在选择最佳模型时，更倾向于使用调整后的 \( R^2 \)，因为它对模型复杂度进行了修正，提供了更为保守和合理的评估。

## 总结

在多元线性回归分析中，\( R^2 \) 和调整后的 \( R^2 \) 是评估模型拟合优度的重要指标。虽然 \( R^2 \) 提供了对模型解释能力的直接测量，但由于其易受自变量数量影响而可能导致过拟合，调整后的 \( R^2 \) 则提供了更为可靠的评估标准。通过合理使用这两个指标，研究者可以更有效地构建和选择适当的回归模型，从而提高分析的准确性与可靠性。